#### 一.Nginx

##### 1.Nginx介绍

​	Nginx ("engine x") 是一个**高性能的 HTTP 和反向代理服务器**,特点是占有内存少，并发能力强，事实上 nginx 的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用 nginx，网站用户有：百度、京东、新浪、网易、腾讯、淘宝等

​	Nginx 是高性能的 HTTP 和反向代理的服务器，处理高并发能力是十分强大的，能经受高负载的考验,有报告表明能支持高达 **50,000** 个并发连接数。

##### 2.正向代理

​	在客户端浏览器配置代理服务器进行指定网站访问

![image-20200229220456822](%E4%B8%80.Nginx.assets/image-20200229220456822.png)

##### 3.反向代理

​	反向代理，客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，再返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器地址

![image-20200229221141579](%E4%B8%80.Nginx.assets/image-20200229221141579.png)

##### 4.负载均衡

​	增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡

![image-20200229221344245](%E4%B8%80.Nginx.assets/image-20200229221344245.png)

##### 5.动静分离

​	为了加快网站的解析速度，可以把动态页面和静态页面有不同的服务器来解析，加快解析速度，降低原来单个服务器的压力

![image-20200229221600767](%E4%B8%80.Nginx.assets/image-20200229221600767.png)

##### 6.Linux安装Nginx

​	详情访问：https://zhuanlan.zhihu.com/p/64263517

​	首先，需要准备安装环境

​	gcc , 安装nginx需要对源码进行编译，依赖gcc环境 直接 **yum install gcc-c++** 就行了

​	pcre，是一个正则表达式库,一样 **yum install -y pcre pcre-devel** 就行了

​	zlib，zlib库主要用来压缩与解压缩, **yum install -y zlib zlib-devel**

​	openssl 看名字就知道开启ssl协议的 **yum install -y openssl openssl-devel**

​	然后，进行下一步

​	使用FileZilla或者别的工具连接linux服务器，上传nginx-1.8.0.tar.gz

​	解压: tar -zxvf nginx-1.8.0.tar.gz

​	cd 解压后的文件夹

​	用Putty或者别的工具连接linux服务器将下面命令拷贝，太长，不建议手敲

​		./configure \

​	编译安装

​	先make再make install

​	cd /usr/local/nginx/sbin 执行命令 ./nginx 快速停止命令 ./nginx -s stop

​	完整停止命令 ./nginx -s quit(好一点)

​	重启命令 ./nginx -s reload

​	nginx安装成功，启动nginx，在浏览器上输入虚拟机的ip地址即可访问虚拟机上的nginx：

![img](%E4%B8%80.Nginx.assets/v2-82b98631d814a2b322480d48edbd7fbb_720w.jpg)

8，出现这个页面就成功，有时不能访问，可能是防火墙的原因，可以试试关闭防火墙看看

![image-20200301180912689](%E4%B8%80.Nginx.assets/image-20200301180912689.png)

![image-20200301180711468](%E4%B8%80.Nginx.assets/image-20200301180711468.png)

​	Nginx默认端口为80端口,开始设置防火墙端口

​	具体指令请参照Linux文件夹下的：十八.常用Linux指令

​	重启之后可以直接在Windows访问80端口：

![image-20200301190904855](%E4%B8%80.Nginx.assets/image-20200301190904855.png)

​	安装完成！

​	具体的启动路径，及方式，参照下图：

![image-20200301191024555](%E4%B8%80.Nginx.assets/image-20200301191024555.png)

​	启动完成，可以访问

##### 7.Nginx常用命令

​	使用nginx操作的命令前提条件：必须进入到nginx的目录中

![image-20200301191401505](%E4%B8%80.Nginx.assets/image-20200301191401505.png)

​	进入sbin目录下

​	查看nginx版本号：

```sh
./nginx -v
```

​	![image-20200301191633591](%E4%B8%80.Nginx.assets/image-20200301191633591.png)

​	启动nginx

```sh
./nginx
```

![image-20200301191903743](%E4%B8%80.Nginx.assets/image-20200301191903743.png)

​	关闭nginx

```sh
./nginx -s stop
```

![image-20200301191752543](%E4%B8%80.Nginx.assets/image-20200301191752543.png)

​	重新加载nginx

```sh
./nginx -s reload
```

![image-20200301192044247](%E4%B8%80.Nginx.assets/image-20200301192044247.png)

##### 8.Nginx配置文件

​	位置：/usr/local/nginx/conf

![image-20200301192251088](%E4%B8%80.Nginx.assets/image-20200301192251088.png)

​	nginx的配置文件由三部分组成：

​		全局块，events块，http块

```yml
# 这是Nginx服务器并发处理的关键配置，worker_processes值越大，可以支持的并发处理量也越多，但是会受到硬件软件等设备的制约
worker_processes  1;
# 这块涉及的指令主要影响Nginx服务器与用户的网络连接，常用的设置包括是否开启对多  work  process下的网络连接进行序列化，是否允许接收多个网络连接，选取那种事件驱动模型来处理连接请求，每个work process可以同时支持的最大连接数等
events {
	# 支持的最大连接数为1024
    worker_connections  1024;
}
# 这部分是Nginx服务器配置中最频繁的部分，代理，缓存，日志等绝大多数功能和第三方模块的配置都在这里,是配置最为频繁的地方
http {
	#http全局块配置的指令包括文件引入，代理，缓存和日志定义等绝大多数功能和第三方配置在这一部分
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;
	#这部分和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本，每个http块可以包含多个server块，每个server块相当于一个虚拟主机，而每个server块也分为全局server块，以及可以同时包含多个location块
    server {
        listen       80; # 监听端口为80端口
        server_name  localhost; # 主机名称
        location / {
            root   html;
            index  index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
	    127.0.0.1:9000
       	/scripts$fastcgi_script_name; 
    }
}
```

##### 9.Nginx配置反向代理

###### 1）实例1

​	实现效果：浏览器输入地址>www.123.com<,跳转到linux系统tomcat主页面

​	首先在Linux中安装tomcat

​	解压tomcat

```sh
tar -xvf apache-tomcat-7.0.70.tar.gz
```

![image-20200302213927820](%E4%B8%80.Nginx.assets/image-20200302213927820.png)

​	进入解压后的文件bin目录

![image-20200302214403221](%E4%B8%80.Nginx.assets/image-20200302214403221.png)

​	执行启动tomcat指令

```sh
./startup.sh
```

![image-20200302214703964](%E4%B8%80.Nginx.assets/image-20200302214703964.png)

​	启动完成

​	添加tomcat的访问端口8080到Linux的防火墙中

```sh
#开启8080端口接收数据
/sbin/iptables -I INPUT -p tcp --dport 5212 -j ACCEPT
#开启8080端口发送数据
/sbin/iptables -I OUTPUT -p tcp --dport 5212 -j ACCEPT
#保存配置
/etc/rc.d/init.d/iptables save
#重启防火墙服务
/etc/rc.d/init.d/iptables restart
```

![image-20200302215123596](%E4%B8%80.Nginx.assets/image-20200302215123596.png)

​	windows访问Linux中的Tomcat

![image-20200302215433859](%E4%B8%80.Nginx.assets/image-20200302215433859.png)

​	访问成功

​	整体结构：

![image-20200302215638508](%E4%B8%80.Nginx.assets/image-20200302215638508.png)

​	首先在host文件中  配置域名映射IP地址

![image-20200302220239639](%E4%B8%80.Nginx.assets/image-20200302220239639.png)

​	测试！

![image-20200302220353802](%E4%B8%80.Nginx.assets/image-20200302220353802.png)

​	在nginx配置反向代理，请求转发，编辑配置文件

![image-20200302220633737](%E4%B8%80.Nginx.assets/image-20200302220633737.png)

![image-20200302221508241](%E4%B8%80.Nginx.assets/image-20200302221508241.png)

​	保存并退出（**上面的是proxy_pass   http:127.0.0.1:8080;**）

​	重启nginx

![image-20200302222157987](%E4%B8%80.Nginx.assets/image-20200302222157987.png)

​	测试

![image-20200302222559783](%E4%B8%80.Nginx.assets/image-20200302222559783.png)

​	反向代理成功！

###### 2）实例2

​	实现效果：

​		使用nginx反向代理，根据访问的路径跳转到不同端口服务中

​		nginx监听端口9001

​		访问http：//192.168.44.130:9001/edu/	直接跳转到127.0.0.1:8080

​		访问http：//192.168.44.130:9001/vod/	直接跳转到127.0.0.1:8081

​	准备2个tomcat服务器，一个是8080端口，一个是8081端口

​	在/usr/src文件路径下创建两个文件夹tomcat8080，tomcat8081

![image-20200302224027336](%E4%B8%80.Nginx.assets/image-20200302224027336.png)

​	停止tomcat

![image-20200302224250173](%E4%B8%80.Nginx.assets/image-20200302224250173.png)

​	将tomcat压缩包放入两个新建文件夹，进行解压

![image-20200302224538508](%E4%B8%80.Nginx.assets/image-20200302224538508.png)

​	直接启动8080端口tomcat

![image-20200302224727183](%E4%B8%80.Nginx.assets/image-20200302224727183.png)

​	进入8081文件夹，进行解压

![image-20200302224933790](%E4%B8%80.Nginx.assets/image-20200302224933790.png)

​	进入conf文件夹中，修改配置文件

![image-20200302225110277](%E4%B8%80.Nginx.assets/image-20200302225110277.png)

​	![image-20200302225235164](%E4%B8%80.Nginx.assets/image-20200302225235164.png)

​	进入bin目录下，直接启动

![image-20200302225419216](%E4%B8%80.Nginx.assets/image-20200302225419216.png)

​	测试

![image-20200302225513516](%E4%B8%80.Nginx.assets/image-20200302225513516.png)

![image-20200302225529888](%E4%B8%80.Nginx.assets/image-20200302225529888.png)

​	tomcat启动完成

​	在8080的webapps文件夹下新建一个文件夹edu，放入一个简单的页面a.html

![image-20200302230229679](%E4%B8%80.Nginx.assets/image-20200302230229679.png)

![image-20200302230326099](%E4%B8%80.Nginx.assets/image-20200302230326099.png)

​	测试

![image-20200302230421384](%E4%B8%80.Nginx.assets/image-20200302230421384.png)

​	同理创建8081文件，并进行测试

![image-20200302230624721](%E4%B8%80.Nginx.assets/image-20200302230624721.png)

​	编写nginx配置文件

![image-20200302230901798](%E4%B8%80.Nginx.assets/image-20200302230901798.png)

​	在配置文件中添加这段配置信息

![image-20200302231548609](%E4%B8%80.Nginx.assets/image-20200302231548609.png)

​	监听端口9001，如果路径中含有edu，就访问8080的tomcat，含有vod，就访问8081的tomcat

​	开放对外访问的端口号9001，8081

![image-20200302231940765](%E4%B8%80.Nginx.assets/image-20200302231940765.png)

​	重启nginx

![image-20200302232122137](%E4%B8%80.Nginx.assets/image-20200302232122137.png)

​	测试

![image-20200302232241537](%E4%B8%80.Nginx.assets/image-20200302232241537.png)

![image-20200302232302356](%E4%B8%80.Nginx.assets/image-20200302232302356.png)

​	测试通过！

##### 10.location特殊含义

​	=	：用于不含正则表达式的uri前，要求请求字符串与uri严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求

​	~	：用于表示uri包含正则表达式，并且区分大小写

​	~*	：用于表示uri包含正则表达式，并且不区分大小写

​	^~	: 用于不含正则表达式的uri前，要求Nginx服务器找到uri和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配

​	**如果uri包含正则表达式，则必须要有    ~    或者    ~*    的标识**

##### 11.负载均衡

​	增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，负载均衡

​	实现效果：

​		浏览器输入地址：http：//192.168.44.130/edu/a.html	负载均衡	分担到8080和8081端口中去

​	准备启动两台tomcat服务器8080,8081，并启动nginx，在两台tomcat里面webapps目录中，创建名称是edu文件夹，在edu文件夹中创建页面a.html，进行测试

​	![image-20200303185233355](%E4%B8%80.Nginx.assets/image-20200303185233355.png)

![image-20200303185340303](%E4%B8%80.Nginx.assets/image-20200303185340303.png)

​	在nginx配置文件中进行负载均衡的配置

![image-20200303185521149](%E4%B8%80.Nginx.assets/image-20200303185521149.png)

![image-20200303191054268](%E4%B8%80.Nginx.assets/image-20200303191054268.png)

​	重启nginx

![image-20200303191206827](%E4%B8%80.Nginx.assets/image-20200303191206827.png)

​	测试

![image-20200303205205291](%E4%B8%80.Nginx.assets/image-20200303205205291.png)

![image-20200303205216655](%E4%B8%80.Nginx.assets/image-20200303205216655.png)

​	同样的路径访问不同端口，测试通过！

```sh
# 新加入一块代码块
upstream myserver{
	server	192.168.44.130:8080;
	server	192.168.44.130:8081;
}
server {
        listen       80;
        # 服务名换为IP地址
        server_name  192.168.44.130;
        location / {
        	# 配置为自己的代理地址
            proxy_pass  http://myserver;
            root   html;
            index  index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }     
```

​	负载均衡算法：

​	第一种 轮询（默认）

​	每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。

​	第二种weight

​	weight代表权重默认为1,权重越高被分配的客户端越多

​	分配给8081的端口的请求多一倍

```sh
upstream myserver{
	server	192.168.44.130:8080 weight=5;
	server	192.168.44.130:8081 weight=10;
}
```

​	第三种 ip_hash

​	每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器

```sh
upstream myserver{
	ip_hash;
	server	192.168.44.130:8080;
	server	192.168.44.130:8081;
}
```

​	第四种fair（第三方）

​	按后端服务器的响应时间来分配请求，响应时间短的优先分配。

```sh
upstream myserver{
	server	192.168.44.130:8080;
	server	192.168.44.130:8081;
	fair;
}
```

##### 12.动静分离

​	使用Nginx处理静态页面，Tomcat处理动态页面，动静分离从目前的实现角度分为两种：

​	1）纯粹将静态文件独立成单独的域名，部署在独立的服务器上，也是目前主流推崇的方案

​	2）动态和静态文件混合在一起发布，通过nginx来分开

![image-20200303214004840](%E4%B8%80.Nginx.assets/image-20200303214004840.png)

​	通过 location 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件，不建议使用 Expires 来缓存），我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重新下载，返回状态码 200。

###### 1）静态资源

​	在Linxu中准备一些静态资源，用于访问

​	在根目录下新建文件夹data，在其中新建两个文件夹

![image-20200303214753983](%E4%B8%80.Nginx.assets/image-20200303214753983.png)

​	在www中新建a.html文件，在image中放入图片1.jpg

###### 2）修改Nginx配置文件

​	![image-20200303215503788](%E4%B8%80.Nginx.assets/image-20200303215503788.png)

```sh
 server {
        listen       80;
        #server_name  localhost;
        server_name  192.168.44.130;
		# 修改location   www   和  /data/ 
        location /www/ {
            root   /data/;
            index  index.html index.htm;
        }
        # 新加一个location
        location /image/ {
            root   /data/;
            autoindex  on;
        }

```

​	测试

![image-20200303220528406](%E4%B8%80.Nginx.assets/image-20200303220528406.png)

​	访问静态资源成功

![image-20200303221131354](%E4%B8%80.Nginx.assets/image-20200303221131354.png)

##### 13.Nginx配置高可用集群

​	当Nginx宕机时，仍然可以正常工作

![image-20200304210340663](%E4%B8%80.Nginx.assets/image-20200304210340663.png)

​	高可用（使用keepalived）![image-20200304211157526](%E4%B8%80.Nginx.assets/image-20200304211157526.png)

![image-20200304211309530](%E4%B8%80.Nginx.assets/image-20200304211309530.png)

​	两台虚拟机服务器，129和131,安装nginx，安装keepalived

​	使用指令安装keepalived

```sh
yum install keepalived -y
```

​		安装成功

![image-20200304212119574](%E4%B8%80.Nginx.assets/image-20200304212119574.png)

​	keepalived安装目录路径配置文件

![image-20200304212321564](%E4%B8%80.Nginx.assets/image-20200304212321564.png)

​	原配置文件内容：

```sh
! Configuration File for keepalived

global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   router_id LVS_DEVEL
}

vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.200.16
        192.168.200.17
        192.168.200.18
    }
}

virtual_server 192.168.200.100 443 {
    delay_loop 6
    lb_algo rr
    lb_kind NAT
    nat_mask 255.255.255.0
    persistence_timeout 50
    protocol TCP

    real_server 192.168.201.100 443 {
        weight 1
        SSL_GET {
            url {
              path /
              digest ff20ad2481f97b1754ef3e12ecd3a9cc
            }
            url {
              path /mrtg/
              digest 9b3a0c85a887a256d6939da88aabd8cd
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }
}

virtual_server 10.10.10.2 1358 {
    delay_loop 6
    lb_algo rr 
    lb_kind NAT
    persistence_timeout 50
    protocol TCP

    sorry_server 192.168.200.200 1358

    real_server 192.168.200.2 1358 {
        weight 1
        HTTP_GET {
            url { 
              path /testurl/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            url { 
              path /testurl2/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            url { 
              path /testurl3/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }

    real_server 192.168.200.3 1358 {
        weight 1
        HTTP_GET {
            url { 
              path /testurl/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334c
            }
            url { 
              path /testurl2/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334c
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }
}

virtual_server 10.10.10.3 1358 {
    delay_loop 3
    lb_algo rr 
    lb_kind NAT
    nat_mask 255.255.255.0
    persistence_timeout 50
    protocol TCP

    real_server 192.168.200.4 1358 {
        weight 1
        HTTP_GET {
            url { 
              path /testurl/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            url { 
              path /testurl2/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            url { 
              path /testurl3/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }

    real_server 192.168.200.5 1358 {
        weight 1
        HTTP_GET {
            url { 
              path /testurl/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            url { 
              path /testurl2/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            url { 
              path /testurl3/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }
}
```

​	修改后配置文件

```sh
global_defs { # 全局配置
 notification_email {
 	acassen@firewall.loc
 	failover@firewall.loc
 	sysadmin@firewall.loc
 }
 notification_email_from Alexandre.Cassen@firewall.loc
 smtp_server 192.168.17.129
 smtp_connect_timeout 30
 router_id LVS_DEVEL	# 访问到主机（在/etc/hosts文件中这个名字映射到主机127.0.0.1）
}
vrrp_script chk_http_port {
 script "/usr/local/src/nginx_check.sh"  # 脚本路径
 interval 2 	#（检测脚本执行的间隔，2秒执行一次）
 weight 2		# 权重，
}
vrrp_instance VI_1 {
 	state BACKUP # 备份服务器上将 MASTER 改为 BACKUP 
 	interface eth0  # 网卡名称
 	virtual_router_id 51 # 主、备机的 virtual_router_id 必须相同
 	priority 90 # 主、备机取不同的优先级，主机值较大，备份机值较小
 	advert_int 1 #时间间隔，每隔多少时间监测心跳
 	authentication {
 		auth_type PASS
 		auth_pass 1111
 	}
 	virtual_ipaddress {
	 192.168.17.50 # 虚拟地址，可以绑定多个
 	} 
}
```

![image-20200304213447362](%E4%B8%80.Nginx.assets/image-20200304213447362.png)

![image-20200304214911752](%E4%B8%80.Nginx.assets/image-20200304214911752.png)

​	在Linux服务器中新建文件/usr/local/src/nginx_check.sh，填入以下内容:

```sh
#!/bin/bash
A=`ps -C nginx –no-header |wc -l`
if [ $A -eq 0 ];then
 /usr/local/nginx/sbin/nginx   #位置
 sleep 2
 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then
 killall keepalived
 fi
fi
```

​	同样在另一台服务器中配置nginx和keepalived，并新建文件/usr/local/src/nginx_check.sh（内容相同）

​	将两台nginx和keepalived启动

```sh
#启动keepalived
systemctl start keepalived.service
```

​	访问192.168.17.50 # VRRP H 虚拟地址（两台nginx绑定到这个虚拟网址）

![image-20200304214416236](%E4%B8%80.Nginx.assets/image-20200304214416236.png)

​	把主服务器停止

![image-20200304214528859](%E4%B8%80.Nginx.assets/image-20200304214528859.png)

​	刷新

![image-20200304214550552](%E4%B8%80.Nginx.assets/image-20200304214550552.png)

​	还是可以访问nginx服务，切换成功

##### 14.Nginx原理

![image-20200304215446975](%E4%B8%80.Nginx.assets/image-20200304215446975.png)

​	启动nginx之后，会有两个进程master和worker

![image-20200304215537233](%E4%B8%80.Nginx.assets/image-20200304215537233.png)

​	![image-20200304220349222](%E4%B8%80.Nginx.assets/image-20200304220349222.png)

​	使用争抢的机制worker去接收client的请求

​	一个 master 和多个 woker 有好处
​	（1）可以使用 nginx –s reload 热部署，利用 nginx 进行热部署操作
​	（2）每个 woker 是独立的进程，如果有其中的一个 woker 出现问题，其他 woker 独立的，继续进行争抢，实现请求过程，不会造成服务中断

​	设置多少个worker

​	Nginx桶Redis类似使用了io多路复用机制，每个worker都是一个独立的进程，但每个进程只有一个主线程，通过异步非阻塞的方式来处理请求，即使是千万个请求也不再话下，每个worker的线程可以把cpu的性能发挥到极致，所以worker数和服务器的cpu数量相等最为合适，少了会浪费cpu的性能，多了会造成cpu频繁的切换上下文的损耗

​	发送一个请求，会占有几个worker数量？（2或者4个）

​	当请求静态资源，一来一回就是两个连接数，连接tomcat的话，来回就是4个连接数

​	nginx 有一个 master，有四个 woker，每个 woker 支持最大的连接数 1024，支持的最大并发数是多少？

​	普通的静态访问最大并发数是： worker_connections * worker_processes /2（1024*4/2），  而如果是 HTTP 作 为反向代理来说，最大并发数量应该是 worker_connections * 
worker_processes/4（4*1024/4）。

​	











